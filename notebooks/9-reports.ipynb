{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.preprocessing import preprocess_func\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize = True\n",
    "preprocess = preprocess_func(lemmatize=lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/row_df_fi.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer'] = df['answer'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_set = list(set([token for a in df['answer'] for token in a.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rajataan data haluttuun organisaatioon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org1 = df['organisaatio1'].value_counts().index[1]\n",
    "\n",
    "is_org1 = df['organisaatio1'] == org1 if org1 else True\n",
    "\n",
    "# org2 = df.loc[is_org1, 'organisaatio2'].value_counts().index[1]\n",
    "org2 = None\n",
    "\n",
    "is_org2 = df['organisaatio2'] == org2 if org2 else True\n",
    "\n",
    "print(f'organisaatio1: {org1}\\norganisaatio2: {org2}')\n",
    "\n",
    "df_sel = df[is_org1 & is_org2]\n",
    "\n",
    "print(len(df_sel))\n",
    "\n",
    "df_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanojen frekvenssin analysointi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stop = ['esim', 'redacted', 'url', 'mm', 'osata', 'kehittää', 'työ', 'taito', 'kehittyä', 'oppia', 'liittyvä', 'osaaminen', 'käyttö', 'lisätä', 'haluta']\n",
    "\n",
    "STOP = set(stopwords.words('finnish') \n",
    "           + open('data/external/stopwords.txt').read().splitlines()\n",
    "           + _stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sel_words = [a for ans in df_sel['answer'] for a in ans.split()]\n",
    "all_sel_words_no_stop = [a for a in all_sel_words if a not in STOP]\n",
    "c = Counter(all_sel_words_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organisaatioille ominaiset sanat (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. select the columns we are interested in\n",
    "# 2. drop nan rows (org not specified)\n",
    "# 3. group by organization\n",
    "# 4. concatenate all documents\n",
    "\n",
    "g = df[['organisaatio1', 'organisaatio2', 'answer']]\\\n",
    ".dropna()\\\n",
    ".groupby(['organisaatio1', 'organisaatio2'])\\\n",
    ".agg(lambda s: ' '.join(chain(*s.str.split())))\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "M = tfidf.fit_transform(g['answer'])\n",
    "\n",
    "# find row index for the selected org1 and org2 pair\n",
    "def org_eq(idx, orgs):\n",
    "    pairs = zip(idx, orgs)\n",
    "\n",
    "    # returns true only if all organizations in `idx` and `orgs` are the same\n",
    "    # and does not do the comparison if element in `orgs` is not truthy\n",
    "    return all(idx_org == org if org else True for idx_org, org in pairs)\n",
    "\n",
    "org_idx = [org_eq(idx, [org1, org2]) for idx in g.index].index(True)\n",
    "\n",
    "\n",
    "sorted([(word, M[org_idx, word_idx]) for word, word_idx in tfidf.vocabulary_.items() if word not in STOP], \n",
    "       key=lambda t: t[1], \n",
    "       reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.read_csv('data/interim/word_clusters_cc.fi.300-lemmatized=True.csv', index_col=0)\n",
    "# cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2cluster = dict(cluster_df[['word', 'cluster']].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counter = Counter([word2cluster[w] for w in all_sel_words if w in word2cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_clusters = cluster_counter.most_common(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top-10 words in 10 most common clusters\n",
    "for i, (cluster, count) in enumerate(top10_clusters):\n",
    "    _cl_df = cluster_df[cluster_df['cluster'] == cluster]\n",
    "    print(f'---- [{i}] CLUSTER {cluster} (count {count}) ----')\n",
    "    print(f\"stopword %: {_cl_df['word'].isin(STOP).mean() * 100}\")\n",
    "#     display(_cl_df.sort_values(by='count', ascending=False).set_index('word')[['count']][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raportin generointi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yleisimmät sanat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_fn(row):\n",
    "    c = Counter(w for w in row['answer'].split() if w not in STOP)\n",
    "    \n",
    "    cols = {'rivien lkm': row['count'], **{f'sana{i}': '' for i in range(1, 1 + top_n_words)}}\n",
    "    \n",
    "    for i, (word, count) in enumerate(c.most_common(n=top_n_words), start=1):\n",
    "        cols[f'sana{i}'] = f'{word} ({count})'\n",
    "        \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanat1 = df.fillna('.N/A')\\\n",
    ".groupby(['organisaatio1'])\\\n",
    ".agg({'answer': lambda s: ' '.join(chain(*s.str.split())), 'lang': 'count'})\\\n",
    ".rename(columns={'lang' : 'count'})\\\n",
    ".apply(top_words_fn, axis=1, result_type='expand')\n",
    "\n",
    "sanat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = df['organisaatio1'] == 'Kaupunginkanslia'\n",
    "# b = df['organisaatio2'] == 'Kaupunginkanslia'\n",
    "\n",
    "# for x in df.loc[a & b, 'answer']:\n",
    "#     print(x)\n",
    "#     print('-'* 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanat2 = df.fillna('.N/A')\\\n",
    ".groupby(['organisaatio1', 'organisaatio2'])\\\n",
    ".agg({'answer': lambda s: ' '.join(chain(*s.str.split())), 'lang': 'count'})\\\n",
    ".rename(columns={'lang' : 'count'})\\\n",
    ".apply(top_words_fn, axis=1, result_type='expand')\n",
    "\n",
    "sanat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanat3 = df.fillna('.N/A')\\\n",
    "# .groupby(['organisaatio1', 'organisaatio2', 'organisaatio3'])\\\n",
    "# .agg({'answer': lambda s: ' '.join(chain(*s.str.split())), 'lang': 'count'})\\\n",
    "# .rename(columns={'lang' : 'count'})\\\n",
    "# .apply(top_words_fn, axis=1, result_type='expand')\n",
    "\n",
    "# sanat3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Sanojen määrät tf-idf painoilla\n",
    "\n",
    "def top_words_tfidf_fn(row):\n",
    "    idx = row['organisaatio1']\n",
    "\n",
    "    org_idx = list(g.index == idx).index(True)\n",
    "    \n",
    "    words = sorted([(word, M[org_idx, word_idx]) for word, word_idx in tfidf.vocabulary_.items() if word not in STOP], \n",
    "           key=lambda t: t[1], \n",
    "           reverse=True)[:top_n_words]\n",
    "\n",
    "    cols = {**{f'sana{i}': w for i, (w, score) in enumerate(words, start=1)}, **row}\n",
    "\n",
    "    return cols\n",
    "\n",
    "g = df.fillna('.N/A')\\\n",
    ".groupby(['organisaatio1'])\\\n",
    ".agg({'answer': lambda s: ' '.join(chain(*s.str.split()))})\n",
    "\n",
    "M = tfidf.fit_transform(g['answer'])\n",
    "\n",
    "\n",
    "df.fillna('.N/A')\\\n",
    ".groupby(['organisaatio1'])\\\n",
    ".count()\\\n",
    ".drop(columns=[col for col in df.columns if col not in ['organisaatio1', 'lang']])\\\n",
    ".rename(columns={'lang': 'rivien lkm'})\\\n",
    ".reset_index()\\\n",
    ".apply(top_words_tfidf_fn, axis=1, result_type='expand')\\\n",
    ".set_index('organisaatio1') -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanojen klusterit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_clusters = 10\n",
    "top_n_cluster_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_clusters_fn(row):\n",
    "    \n",
    "    cols = {'rivien lkm': row['count'], **{f'klusteri{i}': '' for i in range(1, 1 + top_n_clusters)}}\n",
    "    \n",
    "    c = Counter(word2cluster[w] for w in row['answer'].split() if w not in STOP and w in word2cluster)\n",
    "    \n",
    "    for i, (cluster, count) in enumerate(c.most_common(n=top_n_clusters), start=1):\n",
    "        _cl_df = cluster_df[cluster_df['cluster'] == cluster]\n",
    "        cluster_words = ', '.join(_cl_df.sort_values('count', ascending=False)[:top_n_cluster_words]['word'])\n",
    "#         cols[f'klusteri{i}'] = f'lkm: {count}, klusteri: {cluster}, sanat: {cluster_words}'\n",
    "        cols[f'klusteri{i}'] = cluster_words\n",
    "        \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klusterit1 = df.fillna('.N/A')\\\n",
    ".groupby(['organisaatio1'])\\\n",
    ".agg({'answer': lambda s: ' '.join(chain(*s.str.split())), 'lang': 'count'})\\\n",
    ".rename(columns={'lang' : 'count'})\\\n",
    ".apply(word_clusters_fn, axis=1, result_type='expand')\n",
    "\n",
    "klusterit1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klusterit2 = df.fillna('.N/A')\\\n",
    ".groupby(['organisaatio1', 'organisaatio2'])\\\n",
    ".agg({'answer': lambda s: ' '.join(chain(*s.str.split())), 'lang': 'count'})\\\n",
    ".rename(columns={'lang' : 'count'})\\\n",
    ".apply(word_clusters_fn, axis=1, result_type='expand')\n",
    "\n",
    "klusterit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klusterit3 = df.fillna('.N/A')\\\n",
    "# .groupby(['organisaatio1', 'organisaatio2', 'organisaatio3'])\\\n",
    "# .agg({'answer': lambda s: ' '.join(chain(*s.str.split())), 'lang': 'count'})\\\n",
    "# .rename(columns={'lang' : 'count'})\\\n",
    "# .apply(word_clusters_fn, axis=1, result_type='expand')\n",
    "\n",
    "# klusterit3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = df['organisaatio1'].dropna().unique()\n",
    "\n",
    "# columns = ['rivien_lkm'] + [sana + str(k) for sana, k in zip(['klusteri'] * 10, range(1, 11))]\n",
    "\n",
    "# r2 = pd.DataFrame(data=None, index=index, columns=columns)\n",
    "\n",
    "# for org in index:\n",
    "#     org_df = df[df['organisaatio1'] == org]\n",
    "    \n",
    "#     r2.loc[org, 'rivien_lkm'] = len(org_df)\n",
    "    \n",
    "#     org_cluster_counter = Counter([word2cluster[w] for words in org_df['answer'].str.split() for w in words if w in word2cluster])\n",
    "    \n",
    "# #     print(org_cluster_counter)\n",
    "\n",
    "#     for i, (cluster, count) in enumerate(org_cluster_counter.most_common(n=10), start=1):\n",
    "#         _cl_df = cluster_df[cluster_df['cluster'] == cluster]\n",
    "#         cluster_words = ', '.join(_cl_df.sort_values('count', ascending=False)[:10]['word'])\n",
    "# #         display(cluster_words)\n",
    "# #         r2.loc[org, f'klusteri{i}_lkm'] = count\n",
    "#         r2.loc[org, f'klusteri{i}'] = f'({count}) {cluster_words}'\n",
    "\n",
    "\n",
    "# #     break\n",
    "    \n",
    "# display(r2)\n",
    "\n",
    "# r2.to_excel('report/report.xlsx', sheet_name='klusterit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

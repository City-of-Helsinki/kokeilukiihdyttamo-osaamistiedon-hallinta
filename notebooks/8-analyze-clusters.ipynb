{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "from sklearn import metrics, cluster, decomposition, manifold\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as w\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import plotly\n",
    "\n",
    "from utils.preprocessing import preprocess_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize = True\n",
    "preprocess = preprocess_func(lemmatize=lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list available models\n",
    "for p in Path('models').glob('*.bin'):\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'cc.fi.300.bin'\n",
    "model_name = 'fasttext-lr=0.05,dim=30,ws=5,epoch=5,minn=4,maxn=6,neg=10,loss=ns,bucket=2000000,lrUpdateRate=100,t=0.0001,lemmatize=True.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model(f'models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_ft_vec(word):\n",
    "    v = ft.get_word_vector(word)\n",
    "\n",
    "    if np.isclose(v.sum(), 0).all():\n",
    "        return v\n",
    "\n",
    "    return v / np.sqrt(np.sum(v**2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/ensisijainen.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer'] = df['answer'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['answer'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of all words\n",
    "all_words_list = [token for tokens in df['tokens'] for token in tokens]\n",
    "\n",
    "c = Counter(all_words_list)\n",
    "\n",
    "all_words = sorted(list(set(all_words_list)))\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = pd.DataFrame(data=[get_normalized_ft_vec(w) for w in all_words], index=all_words)\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some vectors which do not have word embeddings\n",
    "invalid_words = V.index[(V == 0).all(axis=1)]\n",
    "\n",
    "# drop them from V\n",
    "V = V.drop(index=invalid_words)\n",
    "\n",
    "# and remove them from tokens\n",
    "df['tokens'] = df['tokens'].apply(lambda tokens: [t for t in tokens if t not in invalid_words])\n",
    "\n",
    "# and all_words\n",
    "all_words = [w for w in all_words if w not in invalid_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.sum(V**2, axis=1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_clusters = 100\n",
    "\n",
    "# clustering = cluster.KMeans(n_clusters)\n",
    "\n",
    "# labels = clustering.fit_predict(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer1 = umap.UMAP(n_neighbors=50, n_components=5)\n",
    "\n",
    "embeddings1 = reducer1.fit_transform(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = hdbscan.HDBSCAN(min_cluster_size=5)\n",
    "\n",
    "labels = clustering.fit_predict(embeddings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(pd.Series(labels).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = manifold.TSNE(n_components=2)\n",
    "# embeddings = reducer.fit_transform(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=50)\n",
    "\n",
    "embeddings = reducer.fit_transform(embeddings1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = [lbl for lbl in labels if lbl != -1]\n",
    "embeddings_ = np.stack([embeddings[i] for i, lbl in enumerate(labels) if lbl != -1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.scatter(*zip(*embeddings_), marker='.', c=labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([(w, c[w]) for w in V[labels == -1].index], key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(16, 12))\n",
    "# plt.scatter(*zip(*tsne_embeddings), marker='.', c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KwargContainer:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame({\n",
    "        'word': all_words,\n",
    "        'count': [c[word] for word in all_words],\n",
    "        'cluster': labels})\n",
    "\n",
    "dropdown = w.Dropdown(options=range(n_clusters))\n",
    "\n",
    "output = w.Output()\n",
    "\n",
    "def handle_change(change):\n",
    "    selected_cluster = change.new\n",
    "\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        sel = dd[dd['cluster'] == selected_cluster]\\\n",
    "            .set_index('word')\\\n",
    "            .sort_values('count', ascending=False)[:20]\n",
    "\n",
    "        display(sel)\n",
    "\n",
    "dropdown.observe(handle_change, names='value')\n",
    "\n",
    "handle_change(KwargContainer(new=0)) # send a dummy object to trigger the event handler\n",
    "\n",
    "w.VBox([dropdown, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name.rsplit('.', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv(f\"data/interim/word_clusters_{model_name.rsplit('.', 1)[0]}-lemmatized={lemmatize}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
